{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LuigiSigillo/Aviation-accidents-visualizations/blob/main/Data_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjUjLDVK2dr4"
      },
      "source": [
        "# Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LW5yq-kz-oQe"
      },
      "source": [
        "before preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yhhmGZ22Gq6",
        "outputId": "a25db0a8-3821-4263-9f71-4d8b6437221b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        }
      },
      "source": [
        "import sys\n",
        "import time\n",
        "import os\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "#!unzip \"/content/drive/My Drive/AviationData.csv.zip\" -d \"/content/drive/My Drive/\"\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/My Drive/AviationCrashLocation_3k.csv\", encoding='ISO-8859-1')\n",
        "df"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Event.Id</th>\n",
              "      <th>Event.Date</th>\n",
              "      <th>Location</th>\n",
              "      <th>Aircraft.Damage</th>\n",
              "      <th>Make</th>\n",
              "      <th>Purpose.of.Flight</th>\n",
              "      <th>Total.Fatal.Injuries</th>\n",
              "      <th>Total.Serious.Injuries</th>\n",
              "      <th>Total.Minor.Injuries</th>\n",
              "      <th>Total.Uninjured</th>\n",
              "      <th>Weather.Condition</th>\n",
              "      <th>Broad.Phase.of.Flight</th>\n",
              "      <th>Crash.Location</th>\n",
              "      <th>Crash.Country</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20200502X81549</td>\n",
              "      <td>2020-05-02</td>\n",
              "      <td>PALMYRA, IL</td>\n",
              "      <td>Destroyed</td>\n",
              "      <td>Yakovlev</td>\n",
              "      <td>Personal</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>VMC</td>\n",
              "      <td>MANEUVERING</td>\n",
              "      <td>39.408889,-89.990277</td>\n",
              "      <td>Illinois</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20200413X13054</td>\n",
              "      <td>2020-04-11</td>\n",
              "      <td>Eagle River, AK</td>\n",
              "      <td>Substantial</td>\n",
              "      <td>Cessna</td>\n",
              "      <td>Personal</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>VMC</td>\n",
              "      <td>MANEUVERING</td>\n",
              "      <td>61.351943999999996,-149.548889</td>\n",
              "      <td>Alaska</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20200326X82317</td>\n",
              "      <td>2020-03-25</td>\n",
              "      <td>Waxahachie, TX</td>\n",
              "      <td>Substantial</td>\n",
              "      <td>Cessna</td>\n",
              "      <td>Personal</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>VMC</td>\n",
              "      <td>STANDING</td>\n",
              "      <td>32.448055,-96.913889</td>\n",
              "      <td>Texas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20200324X34735</td>\n",
              "      <td>2020-03-23</td>\n",
              "      <td>Swansboro, NC</td>\n",
              "      <td>Destroyed</td>\n",
              "      <td>Maule</td>\n",
              "      <td>Personal</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>IMC</td>\n",
              "      <td>UNKNOWN</td>\n",
              "      <td>34.416945,-77.034166</td>\n",
              "      <td>Unknown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20200318X22054</td>\n",
              "      <td>2020-03-18</td>\n",
              "      <td>Eagle Creek, OR</td>\n",
              "      <td>Destroyed</td>\n",
              "      <td>Piper</td>\n",
              "      <td>Personal</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>VMC</td>\n",
              "      <td>TAKEOFF</td>\n",
              "      <td>45.352778,-122.340833</td>\n",
              "      <td>Oregon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2628</th>\n",
              "      <td>20200502X81549</td>\n",
              "      <td>2020-05-02</td>\n",
              "      <td>PALMYRA, IL</td>\n",
              "      <td>Destroyed</td>\n",
              "      <td>Yakovlev</td>\n",
              "      <td>Personal</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>VMC</td>\n",
              "      <td>MANEUVERING</td>\n",
              "      <td>39.408889,-89.990277</td>\n",
              "      <td>America Samoa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2629</th>\n",
              "      <td>20200502X81549</td>\n",
              "      <td>2020-05-02</td>\n",
              "      <td>PALMYRA, IL</td>\n",
              "      <td>Destroyed</td>\n",
              "      <td>Yakovlev</td>\n",
              "      <td>Personal</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>VMC</td>\n",
              "      <td>MANEUVERING</td>\n",
              "      <td>39.408889,-89.990277</td>\n",
              "      <td>Guam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2630</th>\n",
              "      <td>20200502X81549</td>\n",
              "      <td>2020-05-02</td>\n",
              "      <td>PALMYRA, IL</td>\n",
              "      <td>Destroyed</td>\n",
              "      <td>Yakovlev</td>\n",
              "      <td>Personal</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>VMC</td>\n",
              "      <td>MANEUVERING</td>\n",
              "      <td>39.408889,-89.990277</td>\n",
              "      <td>Northern Mariana Islands</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2631</th>\n",
              "      <td>20200502X81549</td>\n",
              "      <td>2020-05-02</td>\n",
              "      <td>PALMYRA, IL</td>\n",
              "      <td>Destroyed</td>\n",
              "      <td>Yakovlev</td>\n",
              "      <td>Personal</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>VMC</td>\n",
              "      <td>MANEUVERING</td>\n",
              "      <td>39.408889,-89.990277</td>\n",
              "      <td>Puerto Rico</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2632</th>\n",
              "      <td>20200502X81549</td>\n",
              "      <td>2020-05-02</td>\n",
              "      <td>PALMYRA, IL</td>\n",
              "      <td>Destroyed</td>\n",
              "      <td>Yakovlev</td>\n",
              "      <td>Personal</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>VMC</td>\n",
              "      <td>MANEUVERING</td>\n",
              "      <td>39.408889,-89.990277</td>\n",
              "      <td>Virgin Islands of the United States</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2633 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Event.Id  ...                        Crash.Country\n",
              "0     20200502X81549  ...                             Illinois\n",
              "1     20200413X13054  ...                               Alaska\n",
              "2     20200326X82317  ...                                Texas\n",
              "3     20200324X34735  ...                              Unknown\n",
              "4     20200318X22054  ...                               Oregon\n",
              "...              ...  ...                                  ...\n",
              "2628  20200502X81549  ...                        America Samoa\n",
              "2629  20200502X81549  ...                                 Guam\n",
              "2630  20200502X81549  ...             Northern Mariana Islands\n",
              "2631  20200502X81549  ...                          Puerto Rico\n",
              "2632  20200502X81549  ...  Virgin Islands of the United States\n",
              "\n",
              "[2633 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ca-gMB7fDHC"
      },
      "source": [
        "# After preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63oYr1DBOtEB"
      },
      "source": [
        "import numpy as np\n",
        "df = pd.read_csv(\"/content/drive/My Drive/AviationData.csv\", encoding='ISO-8859-1')\n",
        "\n",
        "#View the dataset\n",
        "print(\"1, intero\", df.shape, \"TOT = \", df.shape[0]*df.shape[1])\n",
        "\n",
        "\n",
        "\n",
        "df = df.drop(\n",
        "    columns=[\"Accident.Number\",\"Airport.Code\",\"Airport.Name\",\"Registration.Number\",\"Engine.Type\",\"FAR.Description\",\"Schedule\",\"Air.Carrier\",\"Report.Status\",\"Publication.Date\"]\n",
        ")\n",
        "print(\"2, senza colonne inutili\", df.shape, \"TOT = \", df.shape[0]*df.shape[1])\n",
        "\n",
        "\n",
        "\n",
        "print(\"__________________________________________\")\n",
        "df = df.drop(df[df[\"Investigation.Type\"] == \"Incident\"].index)\n",
        "df=df.drop(columns=[\"Investigation.Type\"])\n",
        "\n",
        "print(\"3, senza incidents\", df.shape, \"TOT = \", df.shape[0]*df.shape[1])\n",
        "\n",
        "\n",
        "\n",
        "print(\"__________________________________________\")\n",
        "df = df[df[\"Latitude\"].notnull()]\n",
        "df = df[df[\"Longitude\"].notnull()]\n",
        "\n",
        "print(\"4, solo coordinate\", df.shape, \"TOT = \", df.shape[0]*df.shape[1])\n",
        "\n",
        "\n",
        "print(\"__________________________________________\")\n",
        "## Da mettere solo quelli con fatal (#num morti) o non fatal\n",
        "patternDel = \".*Fatal.*\"\n",
        "filter = df[\"Injury.Severity\"].str.contains(patternDel)\n",
        "df = df[filter]\n",
        "\n",
        "print(\"5, solo severity\", df.shape, \"TOT = \", df.shape[0]*df.shape[1])\n",
        "\n",
        "\n",
        "print(\"__________________________________________\")\n",
        "df = df[df[\"Aircraft.Damage\"].notnull()]\n",
        "print(\"6, solo damage\", df.shape, \"TOT = \", df.shape[0]*df.shape[1])\n",
        "df=df.drop(columns=[\"Aircraft.Category\"])\n",
        "\n",
        "'''\n",
        "print(\"__________________________________________\")\n",
        "df = df[df[\"Aircraft.Category\"]==\"Airplane\"]\n",
        "\n",
        "print(\"7, solo airplane\", df.shape, \"TOT = \", df.shape[0]*df.shape[1])\n",
        "\n",
        "print(\"__________________________________________\")\n",
        "df = df[df[\"Amateur.Built\"]==\"No\"]\n",
        "\n",
        "print(\"8, solo non amatoriali\", df.shape, \"TOT = \", df.shape[0]*df.shape[1])\n",
        "'''\n",
        "df=df.drop(columns=[\"Amateur.Built\"])\n",
        "print(\"__________________________________________\")\n",
        "df = df[df[\"Purpose.of.Flight\"].notnull()]\n",
        "df = df[df[\"Purpose.of.Flight\"]!=\"Unknown\"]\n",
        "print(\"9, solo con purpose\", df.shape, \"TOT = \", df.shape[0]*df.shape[1])\n",
        "\n",
        "print(\"__________________________________________\")\n",
        "df = df.dropna(subset=['Total.Fatal.Injuries','Total.Serious.Injuries'], how='all')\n",
        "print(\"10, tutti NAN a casa\", df.shape, \"TOT = \", df.shape[0]*df.shape[1])\n",
        "\n",
        "\n",
        "print(\"__________________________________________\")\n",
        "df = df[df[\"Weather.Condition\"].notnull()]\n",
        "print(\"11, solo con wether\", df.shape, \"TOT = \", df.shape[0]*df.shape[1])\n",
        "\n",
        "print(\"__________________________________________\")\n",
        "df = df[df[\"Broad.Phase.of.Flight\"].notnull()]\n",
        "print(\"12, solo board phase\", df.shape, \"TOT = \", df.shape[0]*df.shape[1])\n",
        "\n",
        "\n",
        "print(\"__________________________________________\")\n",
        "df = df[df[\"Number.of.Engines\"].notnull()]\n",
        "df=df.drop(columns=[\"Number.of.Engines\"])\n",
        "\n",
        "print(\"13, solo motore\", df.shape, \"TOT = \", df.shape[0]*df.shape[1])\n",
        "\n",
        "\n",
        "print(\"__________________________________________\")\n",
        "df = df[df[\"Model\"].notnull()]\n",
        "df = df[df[\"Make\"].notnull()]\n",
        "print(\"14, not nan make e model\", df.shape, \"TOT = \", df.shape[0]*(df.shape[1]-3))\n",
        "\n",
        "\n",
        "\n",
        "print(\"__________________________________________\")\n",
        "df =  df.drop(df[df[\"Country\"] != \"United States\"].index)\n",
        "df=df.drop(columns=[\"Country\"])\n",
        "print(\"15, only USA\", df.shape, \"TOT = \", df.shape[0]*(df.shape[1]-3))\n",
        "\n",
        "\n",
        "\n",
        "df=df.drop(columns=[\"Injury.Severity\"])\n",
        "df=df.drop(columns=[\"Model\"])\n",
        "df[\"Crash.Location\"] = df[\"Latitude\"].astype(str) + \",\" + df[\"Longitude\"].astype(str) \n",
        "df=df.drop(columns=[\"Latitude\"])\n",
        "df=df.drop(columns=[\"Longitude\"])\n",
        "df['Total.Fatal.Injuries'] = df['Total.Fatal.Injuries'].fillna(0)\n",
        "df = df.fillna(0)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "print(\"__________________________________________\")\n",
        "df = df.drop(df[df[\"Injury.Severity\"] == \"Non-Fatal\"].index)\n",
        "df = df.drop(df[df[\"Injury.Severity\"] == \"Unavailable\"].index)\n",
        "print(\"16, solo fatali\", df.shape, \"TOT = \", df.shape[0]*df.shape[1]-3)\n",
        "print(df.head())\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "print(\"__________________________________________\")\n",
        "df = df.drop(df[df[\"Event.Date\"] < \"2015-01-01\"].index)\n",
        "df = df.drop(df[df[\"Injury.Severity\"] == \"Unavailable\"].index)\n",
        "print(\"4, dal 2000 in poi\", df.shape, \"TOT = \", df.shape[0]*(df.shape[1]-3))\n",
        "print(df.head())\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "print(\"TOT = \", df.shape[0]*(df.shape[1]))\n",
        "#df.to_csv(r'/content/drive/My Drive/Aviation cleaned.csv', index = False)\n",
        "df.describe()\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEz1Gx4GehBa"
      },
      "source": [
        "# Coordinates to Country"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qMneJVbendV"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "apiurl = \"http://api.geonames.org/countrySubdivision?\"\n",
        "#lat=42.561944&lng=-71.77166700000001&username=LENZA\n",
        "lat = \"&lat=\"\n",
        "lng = \"&lng=\"\n",
        "user = \"&username=LENZA\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    latlng = row['Crash.Location']\n",
        "\n",
        "    print(str(index) + \" | \" + row['Crash.Location'])\n",
        "    # index -> indice di riga\n",
        "    # row['Crash.Location'] -> latitudine,longitudine\n",
        "    latitude = latlng.split(\",\")[0]\n",
        "    longitude = latlng.split(\",\")[1]\n",
        "    #print(latitude + \" | \" + longitude)\n",
        "    r = requests.get(apiurl + lat + latitude + lng + longitude + user)\n",
        "    print(r)\n",
        "    soup = BeautifulSoup(r.content, 'html.parser')\n",
        "    #print(soup.prettify())\n",
        "    try:\n",
        "        print(soup.adminname1.string)\n",
        "        df.loc[index, 'Crash.Country'] = soup.adminname1.string\n",
        "    except:\n",
        "        df.loc[index, 'Crash.Country'] = \"Unknown\"\n",
        "    #df[index]['Crash.Country'] = soup.adminname1.string\n",
        "    \n",
        "\n",
        "df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnljWrlblvEd"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldMgCDzSvOlc"
      },
      "source": [
        "print(\"TOT = \", df.shape[0]*(df.shape[1]))\n",
        "df.to_csv(r'/content/drive/My Drive/AviationCrashLocation_new.csv', index = False)\n",
        "df.describe()\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDoCXIuT531U"
      },
      "source": [
        "# Aggregation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gW1-g90M_qS"
      },
      "source": [
        "## Aggregate per State"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGCeO_P96CwN"
      },
      "source": [
        "'''\n",
        "per ogni stato serve\n",
        "Incidents -> entries per stato\n",
        "Total.Fatal.Injuries\n",
        "Total.Serious.Injuries\t\n",
        "Total.Minor.Injuries\n",
        "Total.Uninjured\n",
        "Weather.Condition\n",
        "Aircraft.Damage\n",
        "Broad.Phase.of.Flight\n",
        "Make\n",
        "Months\n",
        "Distance\n",
        "'''\n",
        "df = pd.read_csv(\"/content/drive/My Drive/AviationCrashLocation_3k.csv\", encoding='ISO-8859-1')\n",
        "not_usa=[\"Zhambyl\",\"Xinjiang\",\"Qinghai\",\"Inner Mongolia\",\"CaquetÃ¡\",\"Lajas\",\"Tibet\",\"Sonora\",\"Dorado\"]\n",
        "porto_rico = [\"Morovis\",\"San Juan\",\"Arecibo\",\"Adjuntas\"]\n",
        "df['Crash.Country'].replace(not_usa, 'Unknown',inplace=True)\n",
        "df['Crash.Country'].replace(porto_rico, 'Puerto Rico', inplace=True)\n",
        "df['Crash.Country'].replace([\"Saint Croix Island\"], 'Virgin Islands of the United States',inplace=True)\n",
        "\n",
        "groups = df.groupby(by='Crash.Country')\n",
        "groups.groups\n",
        "final_dict = {}\n",
        "for group in groups.groups:\n",
        "    final_dict[group] = {}\n",
        "    final_dict[group]['Incidents'] = len(groups.groups[group])\n",
        "    final_dict[group]['Total.Fatal.Injuries'] = 0\n",
        "    final_dict[group]['Total.Serious.Injuries'] = 0\n",
        "    final_dict[group]['Total.Minor.Injuries'] = 0\n",
        "    final_dict[group]['Total.Uninjured'] = 0\n",
        "    final_dict[group]['Weather.Condition'] = {}\n",
        "    final_dict[group]['Aircraft.Damage'] = {}\n",
        "    final_dict[group]['Broad.Phase.of.Flight'] = {}\n",
        "    final_dict[group]['Make'] = {}\n",
        "    final_dict[group]['Month'] = {}\n",
        "\n",
        "    for index in groups.groups[group]:\n",
        "        final_dict[group]['Total.Fatal.Injuries'] += df['Total.Fatal.Injuries'][index]\n",
        "        final_dict[group]['Total.Serious.Injuries'] += df['Total.Serious.Injuries'][index]\n",
        "        final_dict[group]['Total.Minor.Injuries'] += df['Total.Minor.Injuries'][index]\n",
        "        final_dict[group]['Total.Uninjured'] += df['Total.Uninjured'][index]\n",
        "        try:\n",
        "            final_dict[group]['Weather.Condition'][df['Weather.Condition'][index]] += 1\n",
        "        except:\n",
        "            final_dict[group]['Weather.Condition'][df['Weather.Condition'][index]] = 1\n",
        "\n",
        "        try:\n",
        "            final_dict[group]['Aircraft.Damage'][df['Aircraft.Damage'][index]] += 1\n",
        "        except:\n",
        "            final_dict[group]['Aircraft.Damage'][df['Aircraft.Damage'][index]] = 1\n",
        "\n",
        "        try:\n",
        "            final_dict[group]['Broad.Phase.of.Flight'][df['Broad.Phase.of.Flight'][index]] += 1\n",
        "        except:\n",
        "            final_dict[group]['Broad.Phase.of.Flight'][df['Broad.Phase.of.Flight'][index]] = 1\n",
        "        \n",
        "        try:\n",
        "            final_dict[group]['Make'][df['Make'][index].lower()] += 1\n",
        "        except:\n",
        "            final_dict[group]['Make'][df['Make'][index].lower()] = 1\n",
        "\n",
        "        try:\n",
        "            final_dict[group]['Month'][df['Event.Date'][index].split('-')[1]] += 1\n",
        "        except:\n",
        "            final_dict[group]['Month'][df['Event.Date'][index].split('-')[1]] = 1\n",
        "\n",
        "\n",
        "print(str(final_dict))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFa7neuDLvGS"
      },
      "source": [
        "import json\n",
        "with open(\"/content/drive/My Drive/aggregated_state.json\", \"w\") as write_file:\n",
        "    json.dump(final_dict, write_file, indent=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGmtN8yRhjrW"
      },
      "source": [
        "df = pd.read_json('/content/drive/My Drive/aggregated_state.json')\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASCW1htbNMuM"
      },
      "source": [
        "## Aggregate per Make"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLqk2CesNRAy"
      },
      "source": [
        "'''\n",
        "per ogni stato serve\n",
        "Incidents -> entries per stato\n",
        "Total.Fatal.Injuries\n",
        "Total.Serious.Injuries\t\n",
        "Total.Minor.Injuries\n",
        "Total.Uninjured\n",
        "Weather.Condition\n",
        "Aircraft.Damage\n",
        "Broad.Phase.of.Flight\n",
        "Make\n",
        "Months\n",
        "Distance\n",
        "'''\n",
        "#df.apply(lambda x: x['Make'].astype(str).str.lower())\n",
        "df = pd.read_csv(\"/content/drive/My Drive/AviationCrashLocation.csv\", encoding='ISO-8859-1')\n",
        "groups = df.groupby(df['Make'].str.lower())\n",
        "final_dict = {}\n",
        "for group in groups.groups:\n",
        "    final_dict[group] = {}\n",
        "    final_dict[group]['Incidents'] = len(groups.groups[group])\n",
        "    final_dict[group]['Total.Fatal.Injuries'] = 0\n",
        "    final_dict[group]['Total.Serious.Injuries'] = 0\n",
        "    final_dict[group]['Total.Minor.Injuries'] = 0\n",
        "    final_dict[group]['Total.Uninjured'] = 0\n",
        "    final_dict[group]['Weather.Condition'] = {}\n",
        "    final_dict[group]['Aircraft.Damage'] = {}\n",
        "    final_dict[group]['Broad.Phase.of.Flight'] = {}\n",
        "    final_dict[group]['Crash.Country'] = {}\n",
        "    final_dict[group]['Month'] = {}\n",
        "\n",
        "    for index in groups.groups[group]:\n",
        "        final_dict[group]['Total.Fatal.Injuries'] += df['Total.Fatal.Injuries'][index]\n",
        "        final_dict[group]['Total.Serious.Injuries'] += df['Total.Serious.Injuries'][index]\n",
        "        final_dict[group]['Total.Minor.Injuries'] += df['Total.Minor.Injuries'][index]\n",
        "        final_dict[group]['Total.Uninjured'] += df['Total.Uninjured'][index]\n",
        "        try:\n",
        "            final_dict[group]['Weather.Condition'][df['Weather.Condition'][index]] += 1\n",
        "        except:\n",
        "            final_dict[group]['Weather.Condition'][df['Weather.Condition'][index]] = 1\n",
        "\n",
        "        try:\n",
        "            final_dict[group]['Aircraft.Damage'][df['Aircraft.Damage'][index]] += 1\n",
        "        except:\n",
        "            final_dict[group]['Aircraft.Damage'][df['Aircraft.Damage'][index]] = 1\n",
        "\n",
        "        try:\n",
        "            final_dict[group]['Broad.Phase.of.Flight'][df['Broad.Phase.of.Flight'][index]] += 1\n",
        "        except:\n",
        "            final_dict[group]['Broad.Phase.of.Flight'][df['Broad.Phase.of.Flight'][index]] = 1\n",
        "        \n",
        "        try:\n",
        "            final_dict[group]['Crash.Country'][df['Crash.Country'][index]] += 1\n",
        "        except:\n",
        "            final_dict[group]['Crash.Country'][df['Crash.Country'][index]] = 1\n",
        "\n",
        "        try:\n",
        "            final_dict[group]['Month'][df['Event.Date'][index].split('-')[1]] += 1\n",
        "        except:\n",
        "            final_dict[group]['Month'][df['Event.Date'][index].split('-')[1]] = 1\n",
        "\n",
        "\n",
        "print(str(final_dict))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESKnsrvVNdfK"
      },
      "source": [
        "import json\n",
        "with open(\"/content/drive/My Drive/aggregated_make.json\", \"w\") as write_file:\n",
        "    json.dump(final_dict, write_file, indent=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HX1lR4ZuPnUT"
      },
      "source": [
        "## Aggregate per month"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cyn5021ESwBT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKjEJz17PxKB"
      },
      "source": [
        "'''\n",
        "per ogni stato serve\n",
        "Incidents -> entries per stato\n",
        "Total.Fatal.Injuries\n",
        "Total.Serious.Injuries\t\n",
        "Total.Minor.Injuries\n",
        "Total.Uninjured\n",
        "Weather.Condition\n",
        "Aircraft.Damage\n",
        "Broad.Phase.of.Flight\n",
        "Make\n",
        "Months\n",
        "Distance\n",
        "'''\n",
        "#df.apply(lambda x: x['Make'].astype(str).str.lower())\n",
        "df = pd.read_csv(\"/content/drive/My Drive/AviationCrashLocation.csv\", encoding='ISO-8859-1')\n",
        "for i, row in df.iterrows():\n",
        "    df.at[i,'Event.Date'] = df.at[i,'Event.Date'].split('-')[1]\n",
        "groups = df.groupby(by='Event.Date')\n",
        "final_dict = {}\n",
        "for group in groups.groups:\n",
        "    final_dict[group] = {}\n",
        "    final_dict[group]['Incidents'] = len(groups.groups[group])\n",
        "    final_dict[group]['Total.Fatal.Injuries'] = 0\n",
        "    final_dict[group]['Total.Serious.Injuries'] = 0\n",
        "    final_dict[group]['Total.Minor.Injuries'] = 0\n",
        "    final_dict[group]['Total.Uninjured'] = 0\n",
        "    final_dict[group]['Weather.Condition'] = {}\n",
        "    final_dict[group]['Aircraft.Damage'] = {}\n",
        "    final_dict[group]['Broad.Phase.of.Flight'] = {}\n",
        "    final_dict[group]['Crash.Country'] = {}\n",
        "    final_dict[group]['Make'] = {}\n",
        "\n",
        "    for index in groups.groups[group]:\n",
        "        final_dict[group]['Total.Fatal.Injuries'] += df['Total.Fatal.Injuries'][index]\n",
        "        final_dict[group]['Total.Serious.Injuries'] += df['Total.Serious.Injuries'][index]\n",
        "        final_dict[group]['Total.Minor.Injuries'] += df['Total.Minor.Injuries'][index]\n",
        "        final_dict[group]['Total.Uninjured'] += df['Total.Uninjured'][index]\n",
        "        try:\n",
        "            final_dict[group]['Weather.Condition'][df['Weather.Condition'][index]] += 1\n",
        "        except:\n",
        "            final_dict[group]['Weather.Condition'][df['Weather.Condition'][index]] = 1\n",
        "\n",
        "        try:\n",
        "            final_dict[group]['Aircraft.Damage'][df['Aircraft.Damage'][index]] += 1\n",
        "        except:\n",
        "            final_dict[group]['Aircraft.Damage'][df['Aircraft.Damage'][index]] = 1\n",
        "\n",
        "        try:\n",
        "            final_dict[group]['Broad.Phase.of.Flight'][df['Broad.Phase.of.Flight'][index]] += 1\n",
        "        except:\n",
        "            final_dict[group]['Broad.Phase.of.Flight'][df['Broad.Phase.of.Flight'][index]] = 1\n",
        "        \n",
        "        try:\n",
        "            final_dict[group]['Crash.Country'][df['Crash.Country'][index]] += 1\n",
        "        except:\n",
        "            final_dict[group]['Crash.Country'][df['Crash.Country'][index]] = 1\n",
        "\n",
        "        try:\n",
        "            final_dict[group]['Make'][df['Make'][index].lower()] += 1\n",
        "        except:\n",
        "            final_dict[group]['Make'][df['Make'][index].lower()] = 1\n",
        "\n",
        "\n",
        "print(str(final_dict))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTM2WmMOUifx"
      },
      "source": [
        "import json\n",
        "with open(\"/content/drive/My Drive/aggregated_month.json\", \"w\") as write_file:\n",
        "    json.dump(final_dict, write_file, indent=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZ2yxVljVCB0"
      },
      "source": [
        "!ls '/content/drive/My Drive/' | grep aggregated"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhyXzKeGVVrX"
      },
      "source": [
        "## Aggregate by Phase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fACez-a1VYJJ"
      },
      "source": [
        "'''\n",
        "per ogni stato serve\n",
        "Incidents -> entries per stato\n",
        "Total.Fatal.Injuries\n",
        "Total.Serious.Injuries\t\n",
        "Total.Minor.Injuries\n",
        "Total.Uninjured\n",
        "Weather.Condition\n",
        "Aircraft.Damage\n",
        "Broad.Phase.of.Flight\n",
        "Make\n",
        "Months\n",
        "Distance\n",
        "'''\n",
        "#df.apply(lambda x: x['Make'].astype(str).str.lower())\n",
        "df = pd.read_csv(\"/content/drive/My Drive/AviationCrashLocation.csv\", encoding='ISO-8859-1')\n",
        "groups = df.groupby(df['Broad.Phase.of.Flight'].str.upper())\n",
        "final_dict = {}\n",
        "for group in groups.groups:\n",
        "    final_dict[group] = {}\n",
        "    final_dict[group]['Incidents'] = len(groups.groups[group])\n",
        "    final_dict[group]['Total.Fatal.Injuries'] = 0\n",
        "    final_dict[group]['Total.Serious.Injuries'] = 0\n",
        "    final_dict[group]['Total.Minor.Injuries'] = 0\n",
        "    final_dict[group]['Total.Uninjured'] = 0\n",
        "    final_dict[group]['Weather.Condition'] = {}\n",
        "    final_dict[group]['Aircraft.Damage'] = {}\n",
        "    final_dict[group]['Make'] = {}\n",
        "    final_dict[group]['Crash.Country'] = {}\n",
        "    final_dict[group]['Month'] = {}\n",
        "\n",
        "    for index in groups.groups[group]:\n",
        "        final_dict[group]['Total.Fatal.Injuries'] += df['Total.Fatal.Injuries'][index]\n",
        "        final_dict[group]['Total.Serious.Injuries'] += df['Total.Serious.Injuries'][index]\n",
        "        final_dict[group]['Total.Minor.Injuries'] += df['Total.Minor.Injuries'][index]\n",
        "        final_dict[group]['Total.Uninjured'] += df['Total.Uninjured'][index]\n",
        "        try:\n",
        "            final_dict[group]['Weather.Condition'][df['Weather.Condition'][index]] += 1\n",
        "        except:\n",
        "            final_dict[group]['Weather.Condition'][df['Weather.Condition'][index]] = 1\n",
        "\n",
        "        try:\n",
        "            final_dict[group]['Aircraft.Damage'][df['Aircraft.Damage'][index]] += 1\n",
        "        except:\n",
        "            final_dict[group]['Aircraft.Damage'][df['Aircraft.Damage'][index]] = 1\n",
        "\n",
        "        try:\n",
        "            final_dict[group]['Make'][df['Make'][index].lower()] += 1\n",
        "        except:\n",
        "            final_dict[group]['Make'][df['Make'][index].lower()] = 1\n",
        "            \n",
        "        try:\n",
        "            final_dict[group]['Crash.Country'][df['Crash.Country'][index]] += 1\n",
        "        except:\n",
        "            final_dict[group]['Crash.Country'][df['Crash.Country'][index]] = 1\n",
        "\n",
        "        try:\n",
        "            final_dict[group]['Month'][df['Event.Date'][index].split('-')[1]] += 1\n",
        "        except:\n",
        "            final_dict[group]['Month'][df['Event.Date'][index].split('-')[1]] = 1\n",
        "\n",
        "\n",
        "print(str(final_dict))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhcFhB5yV_aR"
      },
      "source": [
        "import json\n",
        "with open(\"/content/drive/My Drive/aggregated_phase.json\", \"w\") as write_file:\n",
        "    json.dump(final_dict, write_file, indent=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oRVftC2zPMN"
      },
      "source": [
        "# roba"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BPVNryszO3Y",
        "outputId": "5ef3d6a0-4545-47ef-9dd3-e47550efa4e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/My Drive/AviationCrashLocation.csv\", encoding='ISO-8859-1')\n",
        "\"\"\"not_usa=[\"Zhambyl\",\"Xinjiang\",\"Qinghai\",\"Inner Mongolia\",\"CaquetÃ¡\",\"Lajas\",\"Tibet\",\"Sonora\",\"Dorado\"]\n",
        "porto_rico = [\"Morovis\",\"San Juan\",\"Arecibo\",\"Adjuntas\"]\n",
        "df['Crash.Country'].replace(not_usa, 'Unknown',inplace=True)\n",
        "df['Crash.Country'].replace(porto_rico, 'Puerto Rico', inplace=True)\n",
        "df['Crash.Country'].replace([\"Saint Croix Island\"], 'Virgin Islands of the United States',inplace=True)\n",
        "df['Broad.Phase.of.Flight'].replace(['OTHER'], 'UNKNOWN', inplace=True)\n",
        "\"\"\"\n",
        "import pprint, string\n",
        "#df[\"Make\"] = df[\"Make\"].apply(lambda x: x.upper())\n",
        "#df[\"Make\"] = df[\"Make\"].apply(lambda x: \"\".join(word for word in x.translate(str.maketrans('', '', string.punctuation)).split(\" \")))\n",
        "df[\"Make\"] = df[\"Make\"].apply(lambda x: x.upper().split(\" \")[0])\n",
        "pprint.pprint(sorted(df['Make'].unique()))\n",
        "\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['AERO',\n",
            " 'AEROFAB',\n",
            " 'AERONCA',\n",
            " 'AEROPRO',\n",
            " 'AEROS',\n",
            " 'AEROSTAR',\n",
            " 'AEROTEK',\n",
            " 'AEROVODOCHODY',\n",
            " 'AIR',\n",
            " 'AIRBORNE',\n",
            " 'AIRCRAFT',\n",
            " 'AIRPLANE',\n",
            " 'ALON',\n",
            " 'AMERICAN',\n",
            " 'ANTONOVICH',\n",
            " 'APPLEBY',\n",
            " 'ARCTIC',\n",
            " 'ARION',\n",
            " 'AVIAT',\n",
            " 'AYRES',\n",
            " 'BAE',\n",
            " 'BARGER',\n",
            " 'BARROWS',\n",
            " 'BARTELS',\n",
            " 'BEDECORP',\n",
            " 'BEECH',\n",
            " 'BEECHCRAFT',\n",
            " 'BELLANCA',\n",
            " 'BEST',\n",
            " 'BOEING',\n",
            " 'BOEING-STEARMAN',\n",
            " 'BOMBARDIER',\n",
            " 'BRISTELL',\n",
            " 'BRITISH',\n",
            " 'BRM',\n",
            " 'BUCKER',\n",
            " 'BUCKEYE',\n",
            " 'CA',\n",
            " 'CANADAIR',\n",
            " 'CARLO',\n",
            " 'CENTRAL',\n",
            " 'CESSNA',\n",
            " 'CGS',\n",
            " 'CHALLENGER',\n",
            " 'CHAMBERLAIN',\n",
            " 'CHAMPION',\n",
            " 'CHICCO',\n",
            " 'CHRISTEN',\n",
            " 'CIRRUS',\n",
            " 'CITABRIA',\n",
            " 'CLASSIC',\n",
            " 'COLLARD',\n",
            " 'COLONIAL',\n",
            " 'COLUMBIA',\n",
            " 'COLYAER',\n",
            " 'COMMANDER',\n",
            " 'CONSOLIDATED',\n",
            " 'CONVAIR',\n",
            " 'COSTRUZIONI',\n",
            " 'CUB',\n",
            " 'CUBCRAFTERS',\n",
            " 'CULVER',\n",
            " 'CURTISS-WRIGHT',\n",
            " 'CZECH',\n",
            " 'DASSAULT-BREGUET',\n",
            " 'DE',\n",
            " 'DEAN',\n",
            " 'DEHAVILLAND',\n",
            " 'DIAMOND',\n",
            " 'DRAKE',\n",
            " 'DURFEE',\n",
            " 'EAGLE',\n",
            " 'EDWARDS',\n",
            " 'EKORNAAS,',\n",
            " 'EMBRAER',\n",
            " 'EMORY',\n",
            " 'ENGINEERING',\n",
            " 'ERCOUPE',\n",
            " 'ERIS',\n",
            " 'EVEKTOR',\n",
            " 'EVEKTOR-AEROTECHNIK',\n",
            " 'EXTRA',\n",
            " 'FAIRCHILD',\n",
            " 'FANTASY',\n",
            " 'FARTHING',\n",
            " 'FERGUSON',\n",
            " 'FIELDS',\n",
            " 'FISHER',\n",
            " 'FLIGHT',\n",
            " 'FLIGHTSTAR',\n",
            " 'FOCKE-WULF',\n",
            " 'FOLLAND',\n",
            " 'FPNA',\n",
            " 'FRANKE',\n",
            " 'FUJI',\n",
            " 'GATES',\n",
            " 'GENTRY',\n",
            " 'GLASAIR',\n",
            " 'GLOBE',\n",
            " 'GROB',\n",
            " 'GRUMMAN',\n",
            " 'GRUMMAN-SCHWEIZER',\n",
            " 'GULFSTREAM',\n",
            " 'GULFSTREAM-SCHWEIZER',\n",
            " 'HAROLD',\n",
            " 'HAWKER',\n",
            " 'HAWKER-BEECHCRAFT',\n",
            " 'HELIO',\n",
            " 'HELTON',\n",
            " 'HIGGINS',\n",
            " 'HILLARD',\n",
            " 'HOWARD',\n",
            " 'HUGHES',\n",
            " 'ICON',\n",
            " 'INDUS',\n",
            " 'INIZIATIVE',\n",
            " 'INTERPLANE',\n",
            " 'INTERSTATE',\n",
            " 'ISRAEL',\n",
            " 'JABIRU',\n",
            " 'JDT',\n",
            " 'JIHLAVAN',\n",
            " 'KENNETH',\n",
            " 'KESSINGER',\n",
            " 'KOCIEMBA',\n",
            " 'KOLB',\n",
            " 'LANCAIR',\n",
            " 'LANSHE',\n",
            " 'LAWSON',\n",
            " 'LEARJET',\n",
            " 'LIBERTY',\n",
            " 'LOCKHEED',\n",
            " 'LUSCOMBE',\n",
            " 'LUY',\n",
            " 'M',\n",
            " 'M-SQUARED',\n",
            " 'MARSH',\n",
            " 'MASON',\n",
            " 'MAULE',\n",
            " 'MAXAIR',\n",
            " 'MCNULTY',\n",
            " 'MEUER',\n",
            " 'MIKOYAN',\n",
            " 'MITSUBISHI',\n",
            " 'MOONEY',\n",
            " 'MORAVAN',\n",
            " 'MORRISEY',\n",
            " 'MOSES',\n",
            " 'MOYES',\n",
            " 'NANCHANG',\n",
            " 'NAVION',\n",
            " 'NEW',\n",
            " 'NEWGENT,',\n",
            " 'NICHOLS',\n",
            " 'NORTH',\n",
            " 'NORTHWING',\n",
            " 'P&M',\n",
            " 'PARTENAVIA',\n",
            " 'PHANTOM',\n",
            " 'PHILLIPS',\n",
            " 'PILATUS',\n",
            " 'PIPER',\n",
            " 'PIPISTREL',\n",
            " 'PITCAIRN',\n",
            " 'PITTS',\n",
            " 'POTEZ-AIR',\n",
            " 'PROGRESSIVE',\n",
            " 'PZL',\n",
            " 'QUAD',\n",
            " 'QUEST',\n",
            " 'QUICKSILVER',\n",
            " 'RAJHAMSA',\n",
            " 'RANS',\n",
            " 'RAYTHEON',\n",
            " 'REMOS',\n",
            " 'REPUBLIC',\n",
            " 'ROCKWELL',\n",
            " 'ROSE',\n",
            " 'RYAN',\n",
            " 'S',\n",
            " 'S.C.',\n",
            " 'SABRENA',\n",
            " 'SCHWEIZER',\n",
            " 'SCHWEIZER,',\n",
            " 'SEA',\n",
            " 'SHELL',\n",
            " 'SHORT',\n",
            " 'SIAI-MARCHETTI',\n",
            " 'SILER',\n",
            " 'SILVAIRE',\n",
            " 'SKYKITS',\n",
            " 'SLIP',\n",
            " 'SMITH',\n",
            " 'SMITHWICK/TREIDEL',\n",
            " 'SNOW',\n",
            " 'SOCATA',\n",
            " 'SONEX',\n",
            " 'STINSON',\n",
            " 'STOL',\n",
            " 'STORCH',\n",
            " 'SWIFT',\n",
            " 'T',\n",
            " 'TAYLORCRAFT',\n",
            " 'TECNAM',\n",
            " 'TEMCO',\n",
            " 'TEXTRON',\n",
            " 'THOMPSON',\n",
            " 'THRUSH',\n",
            " 'TITAN',\n",
            " 'TL',\n",
            " 'TOMEI',\n",
            " 'TRAVEL',\n",
            " 'TRELLA',\n",
            " 'U-FLY-IT',\n",
            " 'ULTRALIGHT',\n",
            " 'UNIVERSAL',\n",
            " 'UNREGISTERED',\n",
            " 'URBAN',\n",
            " 'VALENTIN',\n",
            " 'VANS',\n",
            " 'VARGA',\n",
            " 'WACO',\n",
            " 'WEATHERLY',\n",
            " 'WICKS',\n",
            " 'WRB',\n",
            " 'WSK',\n",
            " 'X-AIR',\n",
            " 'YAKOVLEV',\n",
            " 'ZENAIR',\n",
            " 'ZENITH']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}